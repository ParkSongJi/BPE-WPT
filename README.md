# WPT 소개(WordPiece Tokenizer)
 
<br>

## 소개

- WordPiece는 2016년도 Google이 BERT를 사전 학습하기 위해 개발한 토큰화 알고리즘 입니다.
- 언어가 가지고 있는 특성을 고려하여 다양하고 풍부한 어휘를 반영하기 위해서 단어를 부분 단어, 즉 subword로 나누어서 처리합니다.
- 또한 BPE와 다르게 특수 토큰이 존재하는데 이 토큰들을 활용해서 OOV 단어 및 문장의 끝맺음 등 다양한 상황에 활용할 수 있습니다.

<br>

## 특수 토큰

- **unk_token**
unk_token은 Unknown 단어를 어떻게 처리할 것인지에 대한 내용이다 기본값은 "[UNK]" token이 되며, 사전에 존재하지 않는 단어인 경우에는 "[UNK]" 으로 표현하게 된다 BERT의 Vocabulary의 경우 30522개의 단어를 포함하고 있는데, 그 외에 단어의 경우 "[UNK]"으로 출력된다.

- **sep_token**
sep_token은 문장의 구분을 지어주기 위해 사용된다. 혹은 문장의 끝을 알려주기 위해 사용된다. 만약 Q&A와 같은 경우 질문에 해당하는 문장이 먼저 들어간 후 답변에 해당하는 문장이 들어올 것이다. 이때 두 문장을 구분지어주기 위해 두 문장 사이에 "[SEP]" token을 사용하여 문장을 구분지어 준다 입력 문장이 하나인 경우에는 문장의 끝을 알려주는 token으로 사용된다.

- **pad_token**
pad_token은 입력 문장의 길이가 다를 때 사용된다. 우리가 입력 문장의 최대 길이를 512로 설정하게 된다면, 문장의 길이가 512보다 작은 경우에는 나머지 값을 "[PAD]"로 채우게 된다. 이때 "[PAD]"는 id가 0이 되며, 별도로 학습을 하지 않는다.

- **cls_token**
cls_token은 "[CLS]" token을 의미하며, 문장의 시작에 들어간다. 문장의 시작으로 사용되는 "[CLS]"는 다른 단어들을 학습할 때 모두 사용되기 때문에 나중에 감성분석을 수행하거나 그럴 때 "[CLS]" token을 호출해 사용한다.

- **mask_token**
Bert는 self-supervised learning 중 하나인 masking 방법을 사용하고 있다. masking 기법은 문장 내에 단어들 중 무작위로 선택하여 masking처리를 하고 해당 단어를 맞추는 형태로 진행하면서 모델의 성능을 향상시키는 기법이다.

<br>

## WPT의 필요성

- **subword tokenizer 의 유연성**
기존의 단어들을 더 작은 subword로 분리하여 언어가 가지고 있는 특성들을 고려해 다양한 어휘들을 표현할 수 있고 OOV와 같은 기존 vocabulary 에 없는 단어들에 대한 대응이 효과적입니다.

- **OOV 대응**
위에서 언급한 내용처럼 vocabulary 안에 없던 단어를 발견했을때 단어를 subword로 분리하여 적은양의 vocabulary 데이터를 통해 처리할 수 있습니다.

- **효율적인 어휘 관리**
어휘의 크기를 동적으로 관리할 수 있는데 빈도가 낮은 subword는 점진적으로 합쳐지며, 적절한 어휘 크기를 유지하면서 모델의 효율성을 높일 수 있습니다.

- **형태소 유지**
단어를 subword로 형태소로 분리하면서 기존에 가지고 있던 정보를 보존하는 의미입니다.
이는 언어가 가지고 있는 특성들을 더 잘 반영할 수 있게 해주며 의미적으로 유사한 subword들을 학습할 수 있습니다.

<br>

## WPT 실행 순서

### 1. 훈련 데이터로부터 단어 빈도수 카운트
- 주어진 훈련 데이터에서 각 단어들의 빈도수를 계산합니다.
- 예시 : 'apple'

### 2. 모든 단어들을 글자(chracter) 단위로 분리
- 훈련 데이터에 있는 모든 단어들을 글자 단위로 분리합니다.
- 가장 앞자리에 위치한 글자를 제외한 나머지 글자들에는 '##' 붙여주고 중복을 제거 합니다.
- 예시 : 'apple' -> 'a', '##'p', '##'p', '##l', '##e'

### 3. 단어가 가질수 있는 병합의 조건을 모두 확인한 후 빈도의 비중이 가장 큰 병합을 하나의 글자로 통합
![KakaoTalk_20240122_144331687](https://github.com/sakongmyoungheun/homework/assets/149550142/6bd6574a-1b12-46d3-9b9b-e89772dc92e0)
- 예시: ('a', '##'p', '##'p', '##l', '##e') -> 'ap', 'pp', 'pl', 'le' 중 'ap'가 가장 높은 비중을 차지한다는 가정을 합니다.
- 업데이트 후 'a', '##'p', '##'p', '##l', '##e' -> 'ap', '##'p', '##l', '##e'

### 4. 반복
- 단계 3의 과정을 원하는 횟수나 기준을 충족할 때까지 반복합니다.
- 예시 : 새로운 상태에서 'ap', '##'p', '##l', '##e' 중에서 빈도가 가장 높은 쌍을 찾아서 통합하고 이를 반복합니다.
